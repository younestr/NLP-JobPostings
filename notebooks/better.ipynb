{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAGGER: This person's primary duties involve t...</td>\n",
       "      <td>Bagger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Institute for Human Neuroscience at Boys T...</td>\n",
       "      <td>Agronomist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About the Company: District Medical Group (DMG...</td>\n",
       "      <td>Autopsy Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Butcher's Table is looking for a part-time...</td>\n",
       "      <td>Butcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Details Job Location : Torrance GSM - TORR...</td>\n",
       "      <td>Autopsy Assistant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label\n",
       "0  BAGGER: This person's primary duties involve t...             Bagger \n",
       "1  The Institute for Human Neuroscience at Boys T...         Agronomist \n",
       "2  About the Company: District Medical Group (DMG...  Autopsy Assistant \n",
       "3  The Butcher's Table is looking for a part-time...            Butcher \n",
       "4  Job Details Job Location : Torrance GSM - TORR...  Autopsy Assistant "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\hp\\Downloads\\NLP-JobPostings\\data\\data_jobs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')      # Tokenizer\n",
    "nltk.download('stopwords')  # Stopwords\n",
    "nltk.download('wordnet')    # WordNet for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers/punkt.zip is available.\n",
      "corpora/stopwords.zip is available.\n",
      "corpora/wordnet.zip is available.\n"
     ]
    }
   ],
   "source": [
    "from nltk.data import find\n",
    "\n",
    "resources = ['tokenizers/punkt.zip', 'corpora/stopwords.zip', 'corpora/wordnet.zip']\n",
    "\n",
    "for resource in resources:\n",
    "    try:\n",
    "        find(resource)\n",
    "        print(f\"{resource} is available.\")\n",
    "    except LookupError:\n",
    "        print(f\"{resource} is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  BAGGER: This person's primary duties involve t...   \n",
      "1  The Institute for Human Neuroscience at Boys T...   \n",
      "2  About the Company: District Medical Group (DMG...   \n",
      "3  The Butcher's Table is looking for a part-time...   \n",
      "4  Job Details Job Location : Torrance GSM - TORR...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [bagger, :, person, 's, primary, duty, involve...  \n",
      "1  [institute, human, neuroscience, boy, town, na...  \n",
      "2  [company, :, district, medical, group, (, dmg,...  \n",
      "3  [butcher, 's, table, looking, part-time, food,...  \n",
      "4  [job, detail, job, location, :, torrance, gsm,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(df[['text', 'tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAGGER: This person's primary duties involve t...</td>\n",
       "      <td>Bagger</td>\n",
       "      <td>[bagger, :, person, 's, primary, duty, involve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Institute for Human Neuroscience at Boys T...</td>\n",
       "      <td>Agronomist</td>\n",
       "      <td>[institute, human, neuroscience, boy, town, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About the Company: District Medical Group (DMG...</td>\n",
       "      <td>Autopsy Assistant</td>\n",
       "      <td>[company, :, district, medical, group, (, dmg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Butcher's Table is looking for a part-time...</td>\n",
       "      <td>Butcher</td>\n",
       "      <td>[butcher, 's, table, looking, part-time, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Details Job Location : Torrance GSM - TORR...</td>\n",
       "      <td>Autopsy Assistant</td>\n",
       "      <td>[job, detail, job, location, :, torrance, gsm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              label  \\\n",
       "0  BAGGER: This person's primary duties involve t...             Bagger   \n",
       "1  The Institute for Human Neuroscience at Boys T...         Agronomist   \n",
       "2  About the Company: District Medical Group (DMG...  Autopsy Assistant   \n",
       "3  The Butcher's Table is looking for a part-time...            Butcher   \n",
       "4  Job Details Job Location : Torrance GSM - TORR...  Autopsy Assistant   \n",
       "\n",
       "                                              tokens  \n",
       "0  [bagger, :, person, 's, primary, duty, involve...  \n",
       "1  [institute, human, neuroscience, boy, town, na...  \n",
       "2  [company, :, district, medical, group, (, dmg,...  \n",
       "3  [butcher, 's, table, looking, part-time, food,...  \n",
       "4  [job, detail, job, location, :, torrance, gsm,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>0000017479</th>\n",
       "      <th>00001</th>\n",
       "      <th>00001491</th>\n",
       "      <th>00005013</th>\n",
       "      <th>00006262</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzinactive</th>\n",
       "      <th>área</th>\n",
       "      <th>áreas</th>\n",
       "      <th>élan</th>\n",
       "      <th>élevage</th>\n",
       "      <th>équivalent</th>\n",
       "      <th>éxito</th>\n",
       "      <th>ía</th>\n",
       "      <th>óptimas</th>\n",
       "      <th>ﬂexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000  0000  00000  000000  0000017479  00001  00001491  \\\n",
       "0  0.000000  0.000000   0.0    0.0     0.0         0.0    0.0       0.0   \n",
       "1  0.000000  0.010968   0.0    0.0     0.0         0.0    0.0       0.0   \n",
       "2  0.000000  0.000000   0.0    0.0     0.0         0.0    0.0       0.0   \n",
       "3  0.000000  0.000000   0.0    0.0     0.0         0.0    0.0       0.0   \n",
       "4  0.017037  0.000000   0.0    0.0     0.0         0.0    0.0       0.0   \n",
       "\n",
       "   00005013  00006262  ...  zzzinactive  área  áreas  élan  élevage  \\\n",
       "0       0.0       0.0  ...          0.0   0.0    0.0   0.0      0.0   \n",
       "1       0.0       0.0  ...          0.0   0.0    0.0   0.0      0.0   \n",
       "2       0.0       0.0  ...          0.0   0.0    0.0   0.0      0.0   \n",
       "3       0.0       0.0  ...          0.0   0.0    0.0   0.0      0.0   \n",
       "4       0.0       0.0  ...          0.0   0.0    0.0   0.0      0.0   \n",
       "\n",
       "   équivalent  éxito   ía  óptimas  ﬂexibility  \n",
       "0         0.0    0.0  0.0      0.0         0.0  \n",
       "1         0.0    0.0  0.0      0.0         0.0  \n",
       "2         0.0    0.0  0.0      0.0         0.0  \n",
       "3         0.0    0.0  0.0      0.0         0.0  \n",
       "4         0.0    0.0  0.0      0.0         0.0  \n",
       "\n",
       "[5 rows x 56705 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib \n",
    "\n",
    "# Join tokens back into a single string for each row\n",
    "df['processed_text'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer_better.joblib\")\n",
    "\n",
    "# TF-IDF matrix to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00            2667\n",
       "000           3382\n",
       "0000             3\n",
       "00000            6\n",
       "000000           2\n",
       "              ... \n",
       "équivalent       2\n",
       "éxito            2\n",
       "ía               2\n",
       "óptimas          2\n",
       "ﬂexibility       2\n",
       "Length: 56705, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "22681    0.0\n",
       "22682    0.0\n",
       "22683    0.0\n",
       "22684    0.0\n",
       "22685    0.0\n",
       "Name: label, Length: 22686, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .............svd__n_components=10000;, score=nan total time=77.0min\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.23 GiB for an array with shape (56705, 10010) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.23 GiB for an array with shape (56705, 10010) and data type float64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'scipy.linalg._decomp_lu_cython.lu_decompose'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\linalg\\_decomp_lu.py\", line 344, in lu\n",
      "    lu_dispatcher(a1, u, p, permute_l)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.23 GiB for an array with shape (56705, 10010) and data type float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = tfidf_df[\"label\"]\n",
    "\n",
    "# Define the pipeline\n",
    "svd = TruncatedSVD()  # Leave n_components unspecified\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('svd', svd),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define the parameter grid: Try different numbers of components\n",
    "param_grid = {\n",
    "    'svd__n_components': [10000, 20000, 30000, 40000]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best number of components\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=3)\n",
    "\n",
    "grid_search.fit(tfidf_matrix, y)  \n",
    "\n",
    "# The best number of components\n",
    "print(\"Best number of components:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_reduced \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(tfidf_matrix)\n\u001b[0;32m      9\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m---> 10\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_reduced, \u001b[43my\u001b[49m)\n\u001b[0;32m     12\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(clf, X_reduced, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validation scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# SVD with n_components=10000\n",
    "svd = TruncatedSVD(n_components=10000)\n",
    "X_reduced = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_reduced, y)\n",
    "\n",
    "scores = cross_val_score(clf, X_reduced, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n",
    "\n",
    "# Save the model and the SVD transformer\n",
    "joblib.dump(clf, 'logistic_regression_model_10000.joblib')\n",
    "joblib.dump(svd, 'svd_transformer_10000.joblib')\n",
    "\n",
    "print(\"Model and SVD transformer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
